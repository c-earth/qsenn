\documentclass[preprint, 12pt]{revtex4-2}
\usepackage{amssymb}
\usepackage{amsmath}
\DeclareMathOperator{\Tr}{Tr}
\usepackage{physics}
\usepackage{xcolor}
\usepackage{mathtools}

\def\thesection{\arabic{section}}
\def\thesubsection{\arabic{section}.\arabic{subsection}}
\def\thesubsubsection{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}}
\numberwithin{equation}{section}

\begin{document}

\title{Unified Representation for Quantum Spin Equivariant Learning}

\author{Abhijatmedhi Chotrattanapituk}
\affiliation{Quantum Measurement Group, MIT, Cambridge, MA, USA \\
            Department of Electrical Engineering and Computer Science, MIT, Cambridge, MA, USA}

\date{\today}

\begin{abstract}
    TBA
\end{abstract}

\maketitle
\newpage

\section{Introduction}

\section{Symmetries in Quantum Spin Systems}

\section{Computational Representation}

\subsection{Systems with Multiple Symmetries.}
Of course, this generalization allow the representations that is not physical, e.g. spin-like object that have odd parity, or time-reversal symmetric object that have half-integer spin. However, it makes things easier to handle in computational perspective since one can represent every physical objects by unified representation with their symmetry descriptions. Not only that, because of the power to control every symmetry included in the representations, the unification grants the opportunity for the computation to easily segregate contributions of interactions with different symmetries. Moreover, from machine learning perspective, there are multiple instances that show better performance when one allow the model to include unphysical symmetries. Lastly, this generalization makes the computational model powerful enough for when, in the future, those unphysical objects are axtually existed.

\newpage
\section{Notations}
Due to the number of groups, and representations discussed in this work, it is important to define some common definitions and notations that would be used. 

\subsection{Group}
A group is a set of items together with a binary operator defined on each pair of elements in the group such that, for an arbritary group of set $G$ and its binary operator $\circ_G$, the following properites must be true.
\begin{enumerate}
    \item For any $g_1, g_2\in G$,
        \begin{equation}\label{eq:group_closed}
            g_1\circ_G g_2\in G.
        \end{equation}
    \item For any $g_1, g_2, g_3\in G$, 
        \begin{equation}\label{eq:group_associative}
            (g_1\circ_G g_2)\circ_G g_3 = g_1\circ_G(g_2\circ_G g_3).
        \end{equation}
    \item There is a unique element $e_G\in G$ such that, for any $g\in G$,
        \begin{equation}\label{eq:group_identity}
            g\circ_G e_G=e_G\circ_G g=g.
        \end{equation}
    \item For any $g\in G$, there is a unique element $g^{-1}\in G$ such that 
        \begin{equation}\label{eq:group_inverse}
            g\circ_G g^{-1}=g^{-1}\circ_G g=e.
        \end{equation}
\end{enumerate}

For compactness in the remaining sections, we would drop the explicit placement of the binary operator and assume the group binary operation whenever there are two elements of the same group placeing beside each other, e.g., if $g_1, g_2\in G$, $g_1g_2\triangleq g_1\circ_G g_2$. Furthermore, we would refer to the group by its set when ever the group's binary operator is unambiguous, e.g., a group of set $G$ and its binary operator $\circ_G$ is group $G$.

\subsection{Homomorphism}
A homomorphism of group $G$ is a map from $G$ to another group $H$ such that the image of $G$ preserves the same structure as $G$. In otherwords, for a homomorphism $h:G\rightarrow H$,
\begin{equation}\label{eq:homomorphism}
    \forall g_1, g_2\in G,\, h(g_1)h(g_2) = h(g_1g_2),
\end{equation}
where the implicit binary operation $g_1g_2$ is from $G$, i.e. $g_1\circ_G g_2$ while implicit binary operation $h(g_1)h(g_2)$ is from $H$, i.e. $h(g_1)\circ_H h(g_2)$.

If a homomorphism is bijective, i.e. each and every element in $H$ is mapped from an element in $G$ homomorphically. The map is called isomorphism, and it entails equivalence relation between isomorphic groups. We denoted group isomorphic equivalence between $G$, and $H$ with $G\cong H$. 

\subsection{Representation}
A group representation of $G$ on vector space $V$ is a group homomorphism from $G$ to general linear group $GL(V)$ which is the group of bijective linear transformation from $V$ to itself. To be more specific, for the vector space $V$ over field $\mathbb{F}_V$ with $n_V$ dimensions, $GL(n_V, \mathbb{F}_V)\triangleq GL(V)$ is the set of $n_V$ by $n_V$ invertible matrices over $\mathbb{F}_V$ with matrix multiplication as the group binary operator. This obviously means that there can be multiple representations depending on the choice of $V$, and each $V$ might has multiple representations as well. 

Assuming that we are able to uniquely name each representation, we would use the notation $D_{G}^{(\Gamma)}:G\rightarrow GL$ for a representation of group $G$ where $\Gamma$ is the label that fully specify the Rep. Since two representations can be equivalence if every corresponding pair of matrix representing group elements are equivalence through the same basis transformation, we would decorate $D_{G}^{(\Gamma)}$ to specify the basis of the matrix representation used.

\subsection{Reducibility of Representation and Irreducible Representation}
A group representation of $G$ on vector space $V$ is reducible if their exist an invariant proper subspace $W\subsetneq V$ such that $W$ is closed under group represented action, i.e.
\begin{equation}\label{eq:invariant subspace}
    \forall g\in G,\,\forall w\in W,\, D_{G}(g)w\in W.
\end{equation}
This reducibility implies that there exists a choice of basis that block diagonalizes group representation such that one of the blocks is a (reduced) group representation of $G$ on vector space $W$.

A group irreducible representation of $G$ is a group representation that is not reducible, i.e. cannot be non-trivially block diagonalized. This criterion is equivalent to Schur's second lemma; given a matrix $M$ and representation of $G$ on vector space $V$, $D_G$, if, for all $g\in G$,
\begin{equation}\label{eq:Schur's second lemma}
    MD_G(g) = D_G(g)M,
\end{equation}
then $M=\lambda I$ for some $\lambda\in \mathbb{F}_V$ where $I$ is an identity matrix.

\subsection{Tensor Product}
Tensor product is an operation to combine vector spaces. It is generally denoted by a bilinear map $U\times V\rightarrow U\otimes V$ such that for any basis vector $\hat{e}_U\in U$, and basis vector $\hat{e}_V\in V$ their tensor product gives a basis vector $\hat{e}_U\otimes \hat{e}_V$. This means that, for any vector $u\in U$, and $v\in V$,
\begin{equation}\label{eq:vector tensor product}
    u\otimes v = \left(\sum_{a}u_a\hat{e}_U^a\right)\otimes\left(\sum_{b}v_b\hat{e}_V^b\right) = \sum_{a,b}u_av_b\hat{e}_U^a\otimes\hat{e}_V^b.
\end{equation}
From this, one can extend the concept to linear maps of tensor product space. Consider two linear maps $S:U\rightarrow U$, and $T:V\rightarrow V$, the tensor product of these two maps is defined as $S\otimes T:U\otimes V\rightarrow U\otimes V$ such that, for any $u\otimes v\in U\otimes V$,
\begin{equation}\label{eq:linear map tensor product}
    (S\otimes T)(u\otimes v) = S(u)\otimes T(v).
\end{equation}
From equation \ref{eq:linear map tensor product}, we can also directly impliy that, if there are $Q:U\rightarrow U$, and $R:V\rightarrow V$,
\begin{equation}\label{eq:compose linear map tensor product}
    (Q\otimes R)(S\otimes T) = QS\otimes RT
\end{equation}

\subsection{Kronecker Product}
Kronecker product is a specialization of tensor product for matrices. Given matrices $M$, and $N$, their Kronecker product is defined as
\begin{equation}\label{eq:Kronecker product}
    \left[M\otimes_KN\right]_{ac,bd} \triangleq \left[M\right]_{a,b}\cdot\left[N\right]_{c,d}.
\end{equation}
Here, the subscripts of the $M\otimes_KN$, i.e. $ac$, and $bd$, are two-digit indices not multiplication. In other words, the resulting product has dimensions of the product of the corresponding dimensions of the compounding matrices, i.e. if $M$ is a $h_M$ by $w_M$ matrix, and $N$ is a $h_N$ by $w_N$ matrix, then $M\otimes_KN$ is a $h_M\cdot h_N$ by $w_M\cdot w_N$ matrix.

Since we would mostly utilize matrix in the form of general linear representation, consider $M\in GL(U)$, and $N\in GL(V)$ with dimensions $n_U$, and $n_V$ respoectively. Because both of them have inverses, we can define
\begin{equation}\label{eq:inverse Kronecker product}
    \left[(M\otimes_KN)^{-1}\right]_{ac,bd} \triangleq \left[M^{-1}\otimes_KN^{-1}\right]_{ac,bd} = \left[M^{-1}\right]_{a,b}\cdot\left[N^{-1}\right]_{c,d}.
\end{equation}
Then,
\begin{equation}\label{eq:Kronecker product GL identity}
    \begin{aligned}
        \left[(M\otimes_KN)(M^{-1}\otimes_KN^{-1})\right]_{ac,ef} &= \sum_{b,d}\left[M\right]_{a,b}\cdot\left[N\right]_{c,d}\cdot\left[M^{-1}\right]_{b,e}\cdot\left[N^{-1}\right]_{d,f} \\
        \left[MM^{-1}\otimes_KNN^{-1}\right]_{ac,ef} &= \left(\sum_{b}\left[M\right]_{a,b}\cdot\left[M^{-1}\right]_{b,e}\right)\left(\sum_{d}\left[N\right]_{c,d}\cdot\left[N^{-1}\right]_{d,f}\right) \\
        \left[I_U\otimes_KI_V\right]_{ac,ef} &= \left[MM^{-1}\right]_{a,e}\cdot\left[NN^{-1}\right]_{c,f} = \left[I_U\right]_{a,e}\cdot\left[I_V\right]_{c,f}
    \end{aligned}
\end{equation}
where $I_U$, and $I_V$ are identity matrices of $U$, and $V$ respectively. This results imply that Kronecker product between invertible matrices of $n_U$, and $n_V$ dimensions is an invertible matrix of $n_U\cdot n_V$ dimensions with matrices and its inverses definded by equation \ref{eq:Kronecker product}, and \ref{eq:inverse Kronecker product}, identity defined by the end of equation \ref{eq:Kronecker product GL identity}, and binary operator defined by equation \ref{eq:compose linear map tensor product}. In other words, Kronecker product between general linear groups of two vector spaces $U$, and $V$ is homomorphic to general linear group of $U\otimes V$.

\subsection{Groups' Direct Product}
A group direct product is a composition of two groups to form a new larger group. Consider groups $G$ and $H$, their direct product is defined as a group of Cartesian product set
\begin{equation}\label{eq:Cartesian product}
    G\times H = \{(g, h)|\forall g\in G,\, \forall h\in H\},
\end{equation}
and its binary operator defined as, $\forall (g_1, h_1), (g_2, h_2)\in G\times H$,
\begin{equation}\label{eq:direct product binary operator}
    (g_1, h_1)(g_2, h_2) = (g_1g_2, h_1h_2).
\end{equation}
Here, we also utilize the implicit binary operation notations.

Consider a pair of representations $D^{(\Gamma_G)}_G$, and $D^{(\Gamma_H)}_H$ of $G$, and $H$ respectively. One can define a representation of $G\times H$ with, for all $g\in G$, and $h\in H$,
\begin{equation}\label{eq:direct product representation}
    D^{(\Gamma_G,\Gamma_H)}_{G\times H}((g,h)) = D^{(\Gamma_G)}_G(g)\otimes_K D^{(\Gamma_H)}_H(h)
\end{equation}
because the structure of groups' direct product (equation \ref{eq:direct product binary operator}) is the same as general linear groups' tensor product (equation \ref{eq:compose linear map tensor product}).

Note that the representation of direct product defined in equation \ref{eq:direct product representation} guarantees irreducible representation from product of two irreducible representation, and complete identification of all irreducible representations of the groups' direct product as long as the groups are either finite, or compact.

\subsection{Free Product}
A group free product is another composition of two groups to form a new larger group. Consider groups $G$ and $H$, their free product ($G\ast H$) is defined as a group generated from $G\cup H$ such that the binary operator is $\circ_G$ between adjacent elements from $G$, and is $\circ_H$ between adjacent elements from $H$,
\begin{equation}\label{eq:free product}
    G\ast H = \bigcup_{N}(G\cup H)^N.
\end{equation}
In other words, $G\ast H$ is a group of arbritary length of words where each words' character is chosen from $G\cup H$. Since $G$, and $H$ are groups, all adjacent elements from $G$ (or $H$) can be replaced by an element from $G$ (or $H$). Hence, $G\ast H$ is actually a group of arbritary length of words where each words' character is alternately chosen from $G$, and $H$. From here, one can specialize free product according to the relation between the compounding groups.

The fact that we are discussing free product of groups is because the operators that apply symmetric transformation from different symmetry groups act on the same system, i.e. vector space. This means that all those operators are actually in the free product group of all considered symmetry group.

\subsection{Free Product of two Commuting Groups}
From previous section, if we also add that $G$, and $H$ are commuting subgroups of $G\ast H$, i.e. $\forall g\in G.\forall h\in H$, $gh=hg$, we can  futher specialize $G\ast H$ by commuting all elements from $G$ to the front of each word (all elements from $H$ are on the backside of each word,) and replacing all adjacent elements from $G$ (or $H$) with and element from $G$ (or $H$). In other words, if $G$, and $H$ commute with each other,
\begin{equation}\label{eq:commute free product}
    G\ast H = \{gh|g\in G, h\in H\}.
\end{equation}
Consider two elements $g_1h_1, g_2h_2\in G\ast H$ where $g_1, g_2\in G$, and $h_1, h_2\in H$,
\begin{equation}\label{eq:commute free product binary operator}
    (g_1h_1)\circ_{G\ast H} (g_2h_2) = g_1h_1g_2h_2=g_1g_2h_1h_2=(g_1\circ_Gg_2)(h_1\circ_Hh_2).
\end{equation}
From free product of commuting groups (equation \ref{eq:commute free product}, and \ref{eq:commute free product binary operator}) and direct product (equation \ref{eq:Cartesian product}, and \ref{eq:direct product binary operator}), we can directly make an isomorphism that maps $gh\in G\ast H$ to $(g,h)\in G\times H$ for every $g\in G$, and $h\in H$. 

This means that $G\ast H\cong G\times H$, and all irreducible representation for free product of commuting groups can be constructed from irreducible representations of the compounding groups according to equation \ref{eq:direct product representation}. This result is very important when we are describing a physical system that contain multiple symmetries which are all commute with each other.

% Leave it at this for now, but might come back for self-sustaining work
\subsection{Reduction of Representation's Product}

\newpage
\section{$SU(2)$ Group}

\subsection{$SU(2)$'s Relation to Quantum Spin System}

\subsection{$SU(2)$'s Definition}
$SU(2)$, i.e. special unitary group of dimension 2, is the group of 2 by 2 unitary matrices with unit determinant with matrix multiplication as its binary operator. In other words,
\begin{equation}\label{eq:SU2}
    SU(2) = \{u \in GL(2, \mathbb{C})|u^\dagger=u^{-1}, \det(u) = 1\},
\end{equation}    
where $u^\dagger$ is the complex conjugate transposition of $u$, and $\det(\cdot)$ is matrix determinant operation. Since, for any $u, v \in SU(2)$,
\begin{equation}\label{eq:determinant identity}
    \det(uv) = \det(u)\det(v) = 1,
\end{equation}
and
\begin{equation}\label{eq:unitary closed}
    (uv)^\dagger = (uv)^{\top\ast} = (v^\top u^\top)^\ast = v^\dagger u^\dagger = v^{-1}u^{-1} = (uv)^{-1},
\end{equation}
$SU(2)$ is a closed subgroup of $GL(2, \mathbb{C})$ which makes it a Lie group. This means that there is a corresponding Lie algebra, $\mathfrak{su(2)}$, such that 
\begin{equation}\label{eq:SU2 Lie group}
    SU(2) = \{e^g|g \in \mathfrak{su(2)}\}
\end{equation}
where the exponential of a square matrix $g$ is defined as
\begin{equation}\label{eq:matrix exponential}
    e^g = I + \sum_{k=1}^{\infty}\dfrac{g^k}{k!}.
\end{equation}
Here, $I$ representes identity matrix with the same shape as $g$. From definition of matrix exponential,
\begin{equation}\label{eq:matrix exponential properties}
    \begin{aligned}
        (e^g)^\dagger &= e^{g^\dagger}, \\
        (e^g)^{-1} &= e^{-g}, \\
        \det(e^g) &= e^{\Tr g},
    \end{aligned}
\end{equation}
one can define the Lie algebra of $SU(2)$ as
\begin{equation}\label{eq:su2}
    \mathfrak{su(2)} = \{g \in M(2, \mathbb{C})|g^\dagger=-g, \Tr(g) = 0\},
\end{equation}
where $M(2,\mathbb{C})$ is the group of 2 by 2 matrices with complex field with matrix multiplication as its binary operator, and $\Tr(\cdot)$ is matrix trace operation. Hence, each member of $\mathfrak{su(2)}$ can be written in the form
\begin{equation}\label{eq:su2 polar angle form}
    \begin{bmatrix}
        iv_z & v_y+iv_x \\
        -v_y+iv_x & -iv_z
    \end{bmatrix}
      = iv_x\sigma_x + iv_y\sigma_y + iv_z\sigma_z = i\vec{v}\cdot\vec{\sigma}
\end{equation}
where $\vec{v} \in \mathbb{R}^3$, $\vec{\sigma}=\sigma_x\hat{x}+\sigma_y\hat{y}+\sigma_z\hat{z}$, and $\sigma_i$'s are Pauli matrices defined as
\begin{equation}\label{eq:Pauli's matrices}
    \sigma_x = \begin{bmatrix}
                    0 & 1 \\
                    1 & 0
                \end{bmatrix},
    \sigma_y = \begin{bmatrix}
                    0 & -i \\
                    i & 0
                \end{bmatrix},
    \sigma_z = \begin{bmatrix}
                    1 & 0 \\
                    0 & -1
                \end{bmatrix}.
\end{equation}

\subsection{$SU(2)$'s Generators}
From $\mathfrak{su(2)}$'s definition in the previous section, one can consider using Pauli matrices as the group generators for $SU(2)$ according to equation \ref{eq:su2 polar angle form}, but it is more common to use $J^{(1/2)}_i \triangleq \sigma_i/2$ as the generators where $i\in \{x, y, z\}$, and $\vec{\phi}\triangleq-2\vec{v}\in\mathbb{R}^3$ as group parameterization. In other words, we can redefine $SU(2)$ as
\begin{equation}\label{eq:SU2 parameterization}
    SU(2) = \{u_{\vec{\phi}}|u_{\vec{\phi}}=e^{-i\vec{J}^{(1/2)}\cdot\vec{\phi}},\, \vec{\phi}\in\mathbb{R}^3\},
\end{equation}
with $\vec{J}^{(1/2)}=J_x^{(1/2)}\hat{x}+J_y^{(1/2)}\hat{y}+J_z^{(1/2)}\hat{z}$. This parameterization of $SU(2)$ group directly implies that
\begin{equation}\label{eq:SU2 parameterization elements}
    \begin{aligned}
        e_{SU(2)} &= u_{\vec{0}}, \\
        u_{\vec{\phi}}^{-1} &= u_{-\vec{\phi}}.
    \end{aligned}
\end{equation}

With this choice of generators, it gives the Lie bracket (commutation) relation
\begin{equation} \label{eq:su2 bracket}
    \left[J^{(1/2)}_i, J^{(1/2)}_j\right] \triangleq J^{(1/2)}_iJ^{(1/2)}_j-J^{(1/2)}_jJ^{(1/2)}_i = i\epsilon_{ijk}J^{(1/2)}_k
\end{equation}
where $\epsilon_{ijk}$ is equal to 1 if $(i, j, k)$ is an even permutation of $(x, y, z)$, $-1$ if odd permutation, and 0 otherwise.

The next step is to consider an arbritary representation of $SU(2)$ such that its generators, represented by $J_i$'s, obey equation \ref{eq:su2 bracket}. With out loss of generality, consider the representation vector space with eigenvectors of $J_z$, $\{\ket{\lambda_{J_z}}\}$, as the basis,
\begin{equation}\label{eq:Jz eigenvalue equation}
    J_z\ket{\lambda_{J_z}}=\lambda_{J_z}\ket{\lambda_{J_z}}.
\end{equation}
Furthermore, we will also assume that this representation is irreducible (proof of this assumption will be in the following section.) With the standard method, first define two additional operators
\begin{equation}\label{eq:ladder operators}
    \begin{aligned}
        J_+ &= J_x + iJ_y, \\
        J_- &= J_x - iJ_y.
    \end{aligned}
\end{equation}
From Lie bracket, and the choice of basis used,
\begin{equation}\label{eq:ladder equation}
    \begin{aligned}
        J_zJ_+\ket{\lambda_{J_z}} &= J_+(J_z+1)\ket{\lambda_{J_z}} = (\lambda_{J_z}+1)J_+\ket{\lambda_{J_z}}, \\
        J_zJ_-\ket{\lambda_{J_z}} &= J_-(J_z-1)\ket{\lambda_{J_z}} = (\lambda_{J_z}-1)J_-\ket{\lambda_{J_z}}.
    \end{aligned}
\end{equation}
This directly implies
\begin{equation}\label{eq:ladder_propto}
    \begin{aligned}
        J_+\ket{\lambda_{J_z}} &\propto \ket{\lambda_{J_z}+1}, \\
        J_-\ket{\lambda_{J_z}} &\propto \ket{\lambda_{J_z}-1}.
    \end{aligned}
\end{equation}

Before proceeding, we need to clarify an assumption we made to get equation \ref{eq:ladder_propto} that there is no degeneracy of $\lambda_{J_z}$ in the basis. This result is directly entailed from the assumption that the representation is irreducible. To prove this, first assume that there exist $\ket{\lambda_{J_z}}'$ that has the same eigenvalue as $\ket{\lambda_{J_z}}$. From the properties of $J_i$'s, we can choose the representation such that equation \ref{eq:ladder_propto} is true, i.e. the operators never create primed vector from unprimed vector. Since the representation of each $SU(2)$ member can be expressed in terms of the generators (equation \ref{eq:SU2 Lie group} and \ref{eq:matrix exponential}), if a subspace is invariant under the generators, it is also invariant under the $SU(2)$ representation. This means that the proper subspace that exclude $\ket{\lambda_{J_z}}'$ is invariant for this choice of representation. Hence, the representation is reducible which contradict the assumption.

To get the proportionality, consider another operators
\begin{equation}\label{eq:J^2}
    J^2 \triangleq J_x^2 + J_y^2+J_z^2.
\end{equation}
One can directly chack that the new operator commutes with all $J$'s mentioned so far. Furthermore, it is straight forward that
\begin{equation}\label{eq:J^2 identity}
    \begin{aligned}
        J^2 &= J_+J_- + J_z^2 - J_z \\
        &= J_-J_+ + J_z^2 + J_z.
    \end{aligned}
\end{equation}
Since $J^2$ commutes with $J_z$, the basis used are also eigenbasis of $J^2$ with some eigenvalue $\lambda_{J^2}$. Hence, we can directly relabel the eigenbasis from $\ket{\lambda_{J_z}}$ to $\ket{\lambda_{J^2}, \lambda_{J_z}}$, and get
\begin{equation}\label{eq:ladder norm square}
    \begin{aligned}
        \mel{\lambda_{J^2}, \lambda_{J_z}}{J_+J_-}{\lambda_{J^2}, \lambda_{J_z}} &= \lambda_{J^2} - \lambda_{J_z}(\lambda_{J_z} - 1), \\
        \mel{\lambda_{J^2}, \lambda_{J_z}}{J_-J_+}{\lambda_{J^2}, \lambda_{J_z}} &= \lambda_{J^2} - \lambda_{J_z}(\lambda_{J_z} + 1).
    \end{aligned}
\end{equation}
Since the norm square of any vector in vector space must be non-negative, this requires
\begin{equation}\label{eq:eigenvalues' condition}
    \lambda_{J^2} \geq \abs{\lambda_{J_z}}(\abs{\lambda_{J_z}}+1) \geq 0.
\end{equation}
However, the $J_\pm$ makes $\lambda_{J_z}$ unbounded unless the vector vanished at some points, i.e. the equality must hold for the upper, and lower bounds of the possible $\lambda_z$'s. If we replace $\lambda_{J^2}$ with $j(j+1)$ where $j$ non-negative. The requirement makes $\lambda_{J_z, \max} = j$, and $\lambda_{J_z, \min} = -j$. Since any pair of $\lambda_{J_z}$'s are different by an integer, 
\begin{equation}\label{eq:eigenvalues' requirement}
    \lambda_{J_z, \max} - \lambda_{J_z, \min} = 2j \in \mathbb{Z}_0^+.
\end{equation}
Hence, we can relabel the eigenbasis from $\ket{\lambda_{J^2}, \lambda_{J_z}}$ to $\ket{j, m}$ and choose the proportionality such that
\begin{equation} \label{eq:J ladder}
    \begin{aligned}
        J_+\ket{j, m} &= \sqrt{j(j+1) - m(m + 1)}\ket{j, m+1}, \\
        J_-\ket{j, m} &= \sqrt{j(j+1) - m(m - 1)}\ket{j, m-1},
    \end{aligned}
\end{equation}
where $j \in \{0, 1/2, 1, 3/2, ...\}$, and $m \in \{-j, -j+1, ..., j-1, j\}$. Next, we must prove that each $j$ fully identifies an irreducible representation. Assuming that this is not the case by letting there be basis vector $\ket{j', m'}$ in the vector space of this irreducible representation that is not linearly dependent on the eigenbasis $\{\ket{j,m}\}$, equation \ref{eq:J ladder} makes the vector space that exclude $\ket{j', m'}$ invariant proper subspace (with reasoning similar to when we prove non-degeneracy of $\lambda_{J_z}$). Hence, this implies the reducibility of the representation which contradicts the assumption. 

\subsection{$SU(2)$'s Irreducible Representations}
In previous section, we have proved that every irreducible representation of $SU(2)$ has its unique $j$ (no irreducible representation requires basis of more than one $j$.) Furthermore, since we have not made any other assumption, $j$ also completely identify every irreducible representation of $SU(2)$ (representations identified by $j$'s exhaust all possible irreducible representations.) In other words, each and every irreducible representation can be uniquely labeled by $j \in \{0, 1/2, 1, 3/2, ...\}$.

Last thing we need to do for that completion of $SU(2)$'s irreducible representation is that the representations labeled by $j$'s (previously assumed to be irreducible) is actually irreducible. Consider a representation of $SU(2)$ that is generated by generators  $J^{(j)}_x$, $J^{(j)}_y$, and $J^{(j)}_z$ where the superscripts indicate that the representation is labeled by $j$. Assuming that this representation is reducible, there must be a unitary basis transformation that nontrivial block diagonalize all elements of $SU(2)$ in this representation. From equation \ref{eq:matrix exponential} and \ref{eq:SU2 parameterization}, the representation labeled by $j$ has, for $\vec{\phi}\in\mathbb{R}^3$,
\begin{equation}\label{eq:SU2 element parameterization}
    u_{\vec{\phi}} = e^{-i\vec{J}^{(j)}\cdot\vec{\phi}} = I+\sum_{k=1}^{\infty}(-i\vec{J}^{(j)}\cdot\vec{\phi})^k,
\end{equation}
as its parameterized matrix representation. Since $\vec{\phi}$ is arbritary, the block diagonalization must holds for every term on the right hand side of equation \ref{eq:SU2 element parameterization}. This implies simultaneous block diagonalization of $J^{(j)}_x$, $J^{(j)}_y$, and $J^{(j)}_z$. In other words, there is an invariant proper subspace, say $W$, that closed under $J^{(j)}_+$, and $J^{(j)}_-$. Since such vector space is a proper subspace, there must exist $-j\leq m'\leq j$ such that the projection of $\ket{j, m'}$ on this space is not $\ket{j, m'}$, i.e. there is nontrivial orthogonal residual. Also, there must exist $-j\leq m''\leq j$ such that the projection of $\ket{j, m''}$ on this space is not zero, i.e. there is nontrivial projection. Let the projection of $\ket{j, m''}$ on to $W$ be
\begin{equation}\label{eq:SU2 projection}
    \text{Proj}_W(\ket{j, m''}) = \sum_{m = -j}^{j}C''_m\ket{j,m}.
\end{equation}
Let the smallest $m$ that $C''_m\neq 0$ be $m^*$. This means that applying $J^{(j)}_+$ for $j-m^*$ times gives nonzero proportional to $\ket{j,j}$, i.e.
\begin{equation}\label{eq:projection extremum}
    \left[J^{(j)}_+\right]^{j-m^*}\text{Proj}_W(\ket{j, m''}) \propto \ket{j, j}.
\end{equation}
After that, apply $J^{(j)}_-$ for $j-m'$ times would also give nonzero proportional to $\ket{j,m'}$, i.e.
\begin{equation}\label{eq:projection to orthogonal}
    \left[J^{(j)}_-\right]^{j-m'}\left[J^{(j)}_+\right]^{j-m^*}\text{Proj}_W(\ket{j, m''}) \propto \ket{j, m'}.
\end{equation}
However, since $\text{Proj}_W(\ket{j, m''})\in W$ and $\ket{j, m'}-\text{Proj}_W(\ket{j, m'})\neq 0$, $W$ is not closed under $J^{(j)}_+$, and $J^{(j)}_-$ which gives contradict. Therefore, the representations we have constructed previously are actually irreducible.

From computational perspective, in order to implement the representation, the basis of the space in which all group operations would act on need to be carefully selected mainly for the purpose of reducing computational costs. However, it requires the consideration of every symmetry group we want to included. Hence, for now, we are assuming the standard $\{\ket{j, m}\}$ basis. In this basis, the irreducible representation labeled with $j$ is the $2j+1$ dimensional space representation. Let the representation of a vector is in the ascending order of the basis from $m = -j$ to $m = j$. We will also, through the rest of this work, index matrices with python-like notation, i.e. indices count from zero. Hence, we can write down
\begin{equation}\label{eq:J's standard basis}
    \begin{aligned}
        \left[J_z^{(j)}\right]_{a,b} &= (a-j)\delta_{a, b}, \\
        \left[J_+^{(j)}\right]_{a,b} &= \sqrt{j(j+1)-(a-j)(b-j)}\delta_{a,b+1}, \\
        J_-^{(j)} &= J_+^{(j)\top}, \\
        J_x^{(j)} &= \left(J_+^{(j)}+J_-^{(j)}\right)/2, \\
        J_y^{(j)} &= -i\left(J_+^{(j)}-J_-^{(j)}\right)/2,
    \end{aligned}
\end{equation}
where $a, b\in \{0, 1, ..., 2j\}$, $j\in \{0, 1/2, 1, 3/2, ...\}$, and $\delta$ is Kronecker delta. Therefore, we can also write down the irreducible representation labeled by $j$ of $u_{\vec{\phi}}\in SU(2)$ with elements parameterized by $\vec{\phi}\in\mathbb{R}^3$ in this basis as
\begin{equation}\label{eq:SU2 Irreps}
    D^{(j)}_{SU(2)}(u_{\vec{\phi}}) = \exp(-i\vec{J}^{(j)}\cdot\vec{\phi}).
\end{equation}

\newpage
\section{$P$ (Parity) Group}

\subsection{$P$'s Relation to Quantum Spin System}

\subsection{$P$'s Definition}
$P$ is the group of spatial inversion, i.e. the group consisting of only 2 elements. The first is its unique identity $e$, and the second is the parity operator $\pi$ (which is its own inverse) that inverts spatial state. The only binary operation rules of this group are
\begin{equation}\label{eq:P binary operations}
    \begin{aligned}
        ee = \pi\pi &= e, \\
        \pi e = e \pi &= \pi.
    \end{aligned}
\end{equation}

\subsection{$P$'s Representations}
From equation \ref{eq:P binary operations}, and the fact that there are only 2 elements in the group, any $n$ dimensional representation of $P$ must be the identity matrix for $e$, and a self-inverse matrix for $\pi$. Since they are both invertible, it is possible to do eigenvalue decomposition of both of them such that
\begin{equation}\label{eq:P eigen decompose}
    \begin{aligned}
        D_P(e) &= UIU^\dagger, \\
        D_P(\pi) &= U\Sigma U^\dagger.
    \end{aligned}
\end{equation}
where $I$ is identity matrix, $\Sigma$ is a diagonal matrix of $D_P(\pi)$'s eigenvalues, and $U$ is the unitary matrix where each column is an eigenvector corresponding to each eigenvalue in $\Sigma$. From this, it is straight forward that all $n$ dimensional representations of $P$ are reducible to 1 dimensional representations.

\subsection{$P$'s Irreducible Representations}
Since 1 dimensional representations cannot be reduced (there is no proper subspace,) all 1 dimensional representations are irreducible representations. From previous section, we now know that all irreducible representations of $P$ must be 1 dimension representation. Furthermore, since $D_P(\pi)$ is self-inverse, $[D_P(\pi)]^2= D_P(e)=1$. Hence, there are only two irriducible representations commonly denoted as even ($D_P(\pi)= 1$), and odd ($D_P(\pi)=-1$). 

We can see that the only difference of these two irreducible representations is in the values of $\pi$'s representations. Therefore, we can directly use those values as the irreducible representations' labels as
\begin{equation}\label{eq:P Irreps}
    \begin{aligned}
        D_P^{(p)}(e) &= 1 \\
        D_P^{(p)}(\pi) &= p
    \end{aligned}
\end{equation}
where the superscripts indicate that the representation is labeled by $p\in \{-1, 1\}$. For convenience in equation writing, we would parameterize this group, even though there are only two elements in the group, by defining
\begin{equation}\label{eq:P parameterization}
    P = \{v_\rho|v_\rho=\pi^\rho,\rho\in\mathbb{Z}_{0+}\}.
\end{equation}
With this notation, we can see that $v_\rho=e$ when $\rho$ is an even number while $v_\rho=\pi$ when $\rho$ is odd. Furthermore, equation \ref{eq:P Irreps} can be greatly simplified to
\begin{equation}\label{eq:P Irreps simplify}
    D_P^{(p)}(v_\rho) = p^\rho.
\end{equation}

\subsection{$SU(2)\times P$'s Irreducible Representations}
After the analysis of two symmetry groups related to quantum spin systems, it is the point where we start unifying them to generalize the way to represent quantum spin system. From the postulation for parity in quantum mechanics, it directly shows that $SU(2)$, and $P$ are commuting groups. This means that $SU(2)\ast P\cong SU(2)\times P$, i.e. the symmetry group that governs the combined symmetries is isomorphic to their direct product group, which makes the tensor product between every pair of irreducible representations of $SU(2)$, and $P$ are irreducible representation of $SU(2)\ast P$, and exhaust all of its possible irreducible representations. Hence, the irreducible representations of the combined $SU(2)$, and $P$ symmetries can be written, labeled with $j$ and $p$, as, for all $u_{\vec{\phi}}\in SU(2)$, and $v_\rho \in P$,
\begin{equation}\label{eq:SU2*P Irreps}
    \begin{aligned}
        D^{(j,p)}_{SU(2)\ast P}(u_{\vec{\phi}} v_\rho) &= D^{(j,p)}_{SU(2)\times P}((u_{\vec{\phi}},v_\rho)) \\
        &= D^{(j)}_{SU(2)}(u_{\vec{\phi}})\otimes D^{(p)}_{P}(v_\rho) \\
        &= \exp(-i\vec{J}^{(j)}\cdot\vec{\phi})\cdot p^\rho
    \end{aligned}
\end{equation}
where $\vec{\phi}\in\mathbb{R}^3$, $\rho\in\mathbb{Z}_{0+}$, $j\in\{0, 1/2, 1, 3/2, ...\}$, and $p\in\{-1, 1\}$. Also, if one choose the standard angular momentum basis, $\vec{J}^{(j)}$ is according to equation \ref{eq:J's standard basis}. The basis for this representation is $\{\ket{j,m}\otimes\ket{p}\}$. However, since $P$'s irreducible representations are all one dimensional, we will denote such basis as $\{\ket{j,m}_p\}$.

\newpage
\section{$T$ (Time-Reversal) Group}

\subsection{$T$'s Relation to Quantum Spin System}

\subsection{$T$'s Definition}
$T$ is the group of temporal inversion, i.e. the group consisting of only 1 generator, the time-reversal operator $\theta$ which is an antiunitary operator.

\subsection{$T$'s Corepresentations}
Because of the antiunitary nature of $T$, the analysis for its irreducible representation cannot be done in the same fashion as other unitary groups. The main reason for this is that the complex conjugation part of the antiunitary operator $\theta$ can change the basis used for the irreducible representation of other groups, i.e. the groups that we want to combine with $T$.

Let assume that the group we want to combine with $T$ is $G$. To proceed from this point, we need to consider the effects of $\theta$ on the basis chosen for $G$'s irreducible representations. Without loss of generality, let $\{\ket{g_a}\}$ be such basis, and the irreducible representation is $D_G$. Hence, for any $g\in G$,
\begin{equation}\label{eq:G irreps act on basis}
    \begin{aligned}
        g\ket{g_a} &= D_G(g)\ket{g_a} \\
        &= \left(\sum_{b, c}\ket{g_b}\left[D_G(g)\right]_{b, c}\bra{g_c}\right)\ket{g_a} \\
        &= \sum_{b}\ket{g_b}\left[D_G(g)\right]_{b, a}.
    \end{aligned}
\end{equation}
Likewise, let the irreducible representation of $g$ in $\{\theta\ket{g_i}\}$ basis be $\tilde{D}_G$, i.e.
\begin{equation}\label{eq:G irreps act on theta basis}
    \begin{aligned}
        g\theta\ket{g_a} &= \tilde{D}_G(g)\theta\ket{g_a} \\
        &= \sum_{b}\theta\ket{g_b}\left[\tilde{D}_G(g)\right]_{b, a}.
    \end{aligned}
\end{equation}
Then apply $\theta^{-1}$ to both side,
\begin{equation}\label{eq:modify G irreps act on theta basis}
    \begin{aligned}
        \theta^{-1}g\theta\ket{g_a} &= \theta^{-1}\left(\sum_{b}\theta\ket{g_b}\left[\tilde{D}_G(g)\right]_{b, a}\right) \\
        &= \sum_{b}\ket{g_b}\left[\tilde{D}_G(g)\right]_{b, a}^\ast \\
        &= \sum_{b}\ket{g_b}\left[\tilde{D}_G^\ast(g)\right]_{b, a}.
    \end{aligned}
\end{equation}
Since multiplication of two antiunitary operator is unitary, and
\begin{equation}\label{eq:modify G}
    \theta^{-1}G\theta\triangleq\{\theta^{-1}g\theta|g\in G\}\cong G
\end{equation}
with isomorphism that maps $\theta^{-1}g\theta$ to $g$, there must be irreducible representation $D_G(\theta^{-1}g\theta)$. By comparing equation \ref{eq:G irreps act on basis}, and \ref{eq:modify G irreps act on theta basis}, one can conclude that
\begin{equation}\label{eq:modify G irreps}
    \begin{aligned}
        \tilde{D}_G^\ast(g) &= D_G(\theta^{-1}g\theta), \\
        \tilde{D}_G(g) &= D_G^\ast(\theta^{-1}g\theta).
    \end{aligned}
\end{equation}

Repeat this one more time for $\{\theta^2\ket{g_i}\}$ basis with irreducible representation $\tilde{\tilde{D}}_G$. We get
\begin{equation}\label{eq:theta theta basis G irreps}
    \begin{aligned}
        \tilde{\tilde{D}}_G(g) &= \tilde{D}^\ast_G(\theta^{-1}g\theta), \\
        &= D_G(\theta^{-2}g\theta^2).
    \end{aligned}
\end{equation}
Here, the first equality follows the logical proof of $\tilde{D}_G$ while the second equality directly uses equation \ref{eq:modify G irreps}. Since $\theta^2$ is unitary, there must be a unitary transformation $\Theta$ such that
\begin{equation}\label{eq:theta theta basis equivalence}
    D_G(\theta^{-2}g\theta^2) = \Theta^\dagger D_G(g)\Theta.
\end{equation}

Equation \ref{eq:theta theta basis equivalence} guarantees that, in order to represent $G\ast T$, one need to only double the basis that represents $G$. Therefore, from equation \ref{eq:G irreps act on basis}, \ref{eq:G irreps act on theta basis}, and \ref{eq:theta theta basis equivalence}, the corepresentations of the combined $G$, and $T$ groups, $D_{G\ast T}$, can be extended from $D_{G}$ by using $\{\ket{g_a}\}\cup\{\theta\ket{g_a}\}$ basis as, for any $g\in G$,
\begin{equation}\label{eq:G*T Coreps}
    \begin{aligned}
        D_{G\ast T}(g) &=   \begin{bmatrix}
                                D_{G}(g) & 0 \\
                                0 & D_{G}^\ast(\theta^{-1}g\theta)  
                            \end{bmatrix}, \\
        D_{G\ast T}(\theta) &=  \begin{bmatrix}
                                    0 & \Theta \\
                                    I & 0 
                                \end{bmatrix},
    \end{aligned}
\end{equation}
where the first half of the basis is $\{\ket{g_a}\}$, the second half of the basis is $\{\theta\ket{g_a}\}$, and $I$ is identity matrix. Note that whether these corepresentation is reducible or not depends on the actual form of $D_{G}(\theta^{-1}g\theta)$, and $\Theta$, but it is guaranteed to exhaust all possible irreducible corepresentations.

Our analysis so far only concerns about the effect of $\theta$ on the basis, but its complex conjugation also applies to other corepresentations, i.e., for all $g, g_1, g_2\in G$,
\begin{equation}\label{eq:G*T composition}
    \begin{aligned}
        D_{G\ast T}(g_1g_2) &= D_{G\ast T}(g_1)D_{G\ast T}(g_2), \\
        D_{G\ast T}(g\theta) &= D_{G\ast T}(g)D_{G\ast T}(\theta), \\
        D_{G\ast T}(\theta g) &= D_{G\ast T}(\theta)D_{G\ast T}^\ast(g), \\
        D_{G\ast T}(\theta\theta) &= D_{G\ast T}(\theta)D_{G\ast T}^\ast(\theta).
    \end{aligned}
\end{equation}
As well as the whole corepresentation vector space, $V$, i.e., for all $g\in G$, and $v\in V$,
\begin{equation}\label{eq:G*T vector space}
    \begin{aligned}
        g\vec{v} &= D_{G\ast T}(g)\vec{v}, \\
        \theta\vec{v} &= D_{G\ast T}(\theta)\vec{v}^\ast.
    \end{aligned}
\end{equation}

Further simplification can be done in the case that $\tilde{D}_G$ is equivalent to $D_G$. In other words, there must exists a unitary basis transformation $U$ that
\begin{equation}\label{eq:theta G basis equivalence}
    \tilde{D}_G(g) = D^\ast_G(\theta^{-1}g\theta) = U^\dagger D_G(g)U.
\end{equation}
This directly makes
\begin{equation}\label{eq:G*T Coreps theta equivalence}
    \begin{aligned}
        D_{G\ast T}(g) &=   \begin{bmatrix}
                                D_{G}(g) & 0 \\
                                0 & U^\dagger D_G(g)U  
                            \end{bmatrix}, \\
        D_{G\ast T}(\theta) &=  \begin{bmatrix}
                                    0 & \Theta \\
                                    I & 0 
                                \end{bmatrix}.
    \end{aligned}
\end{equation}
It also implies, from equation \ref{eq:theta theta basis G irreps}, that
\begin{equation}\label{eq:theta theta G basis equivalence}
    \begin{aligned}
        \tilde{\tilde{D}}_G(g) &= \tilde{D}^\ast_G(\theta^{-1}g\theta), \\
        &= \left(U^\dagger D_G(\theta^{-1}g\theta)U\right)^\ast \\
        &= \left(U^\dagger \tilde{D}_G^\ast(g)U\right)^\ast \\
        &= \left(U^\dagger U^{\dagger\ast} D_G^\ast(g)U^\ast U\right)^\ast \\
        &= \left(UU^\ast\right)^\dagger D_G(g)\left(UU^\ast\right).
    \end{aligned}
\end{equation}
From equation \ref{eq:theta theta basis equivalence}, this also makes
\begin{equation}\label{eq:equate G basis equivalence}
    \begin{aligned}
        \Theta^\dagger D_G(g)\Theta &= \left(UU^\ast\right)^\dagger D_G(g)\left(UU^\ast\right) \\
        \left(UU^\ast\right)\Theta^\dagger D_G(g) &=  D_G(g)\left(UU^\ast\right)\Theta^\dagger
    \end{aligned}
\end{equation}
Because $D_G$ is irreducible, from Schur's second lemma (equation \ref{eq:Schur's second lemma}), $\left(UU^\ast\right)\Theta^\dagger$ must equal a constant $\lambda I$ where $\lambda\in\mathbb{C}$ (assume representation in complex vector space,)
\begin{equation}\label{eq:G basis equivalence}
    UU^\ast = \lambda\Theta.
\end{equation}

Moreover, this basis transformation must also apply to $\Theta$ in the same manner, i.e.
\begin{equation}\label{eq:theta equivalence of theta theta equivalence}
    \tilde{\Theta} = U^\dagger \Theta U.
\end{equation}
Hence,
\begin{equation}\label{eq:theta theta theta G basis equivalence}
    \begin{aligned}
        \tilde{D}_G(\theta^{-2}g\theta^2) &= D_G^\ast(\theta^{-3}g\theta^3) \\
        &= \left(\Theta^\dagger D_G(\theta^{-1}g\theta)\Theta\right)^\ast \\
        &= \Theta^{\dagger\ast} D_G^\ast(\theta^{-1}g\theta)\Theta^\ast \\
        &= \Theta^{\dagger\ast} \tilde{D}_G(g)\Theta^\ast \\
        &\triangleq \tilde{\Theta}^\dagger\tilde{D}_G(g)\tilde{\Theta}
    \end{aligned}
\end{equation}
or
\begin{equation}\label{eq:evaluate theta equivalence of theta theta equivalence}
    U^\dagger \Theta U = \Theta^\ast
\end{equation}
Then, from equation \ref{eq:G basis equivalence}, and \ref{eq:evaluate theta equivalence of theta theta equivalence},
\begin{equation}
    \begin{aligned}
        U^\dagger\left(UU^\ast\right)U &= U^\dagger\left(\lambda\Theta\right)U \\
        U^\ast U &= \lambda U^\dagger \Theta U \\
        \left(UU^\ast\right)^\ast &= \lambda \Theta^\ast \\
        UU^\ast &= \lambda^\ast\Theta,
    \end{aligned}
\end{equation}
which, together with equation \ref{eq:G basis equivalence}, implies that $\lambda\in\mathbb{R}$. Since $U$, and $\Theta$ are unitary, we also know that $|\lambda|=1$. Therefore, $\lambda\in\{-1,1\}$.

Hence, we can further simplify equation \ref{eq:G*T Coreps theta equivalence} into
\begin{equation}\label{eq:G*T Coreps simplify}
    \begin{aligned}
        D_{G\ast T}(g) &=   \begin{bmatrix}
                                D_{G}(g) & 0 \\
                                0 & U^\dagger D_G(g)U  
                            \end{bmatrix}, \\
        D_{G\ast T}(\theta) &=  \begin{bmatrix}
                                    0 & UU^\ast/\lambda \\
                                    I & 0 
                                \end{bmatrix},
    \end{aligned}
\end{equation}
and, with a change of basis from $\{\ket{g_a}\}\cup\{\theta\ket{g_a}\}$ to $\{\ket{g_a}\}\cup\{U^\dagger\theta\ket{g_a}\}$, we get
\begin{equation}\label{eq:G*T Coreps simplify change basis}
    \begin{aligned}
        D_{G\ast T}(g) &=   \begin{bmatrix}
                                D_{G}(g) & 0 \\
                                0 & D_G(g)  
                            \end{bmatrix}, \\
        D_{G\ast T}(\theta) &=  \begin{bmatrix}
                                    0 & U/\lambda \\
                                    U & 0 
                                \end{bmatrix}.
    \end{aligned}
\end{equation}

For convenience in equation writing, we would parameterize this group as well by defining
\begin{equation}\label{eq:T parameterization}
    T = \{w_\tau|w_\tau=\theta^\tau,\tau\in\mathbb{Z}_{0+}\}.
\end{equation}
With this notation, we can see that $w_0=e$, $w_1=\theta$, $w_2=\theta^2$, and so on.

\subsection{$SU(2)\times P\times T$'s Irreducible Corepresentations}
From the postulation for time-reversal in quantum mechanics, it directly shows that $SU(2)$, $P$, and $T$ are commuting groups. This means that $SU(2)\ast P\ast T\cong SU(2)\times P\times T$, but, since $T$ is antiunitary, we need to use analysis in the previous section instead of directly use representation tensor product as in the case of combining $SU(2)$ with $P$.

Using equation \ref{eq:SU2*P Irreps} as the irreducible representation for $SU(2)\times P$ and the commutation of the groups, equation \ref{eq:modify G irreps}, and \ref{eq:theta theta basis equivalence} turn out to be
\begin{equation}\label{eq:modify SU2*P irreps}
    \tilde{D}_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho)) = D_{SU(2)\times P}^{(j,p)\ast}((u_{\vec{\phi}}, v_\rho)),
\end{equation}
and
\begin{equation}\label{eq:theta theta SU2*P basis equivalence}
   D_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho)) = \Theta^{(j,p)\dagger} D_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho))\Theta^{(j,p)},
\end{equation}
where $u_{\vec{\phi}}\in SU(2)$, $v_\rho\in P$, $j\in \{0, 1/2, 1, 3/2, ...\}$, $p\in\{-1, 1\}$, and the irreducible representations $D_{SU(2)\times P}^{(j,p)}$ are in standard basis.

Since $j$, and $p$ completely identifies all $SU(2)\times P$'s irreducible representations of $2j+1$ dimensions, and $\tilde{D}_{SU(2)\times P}^{(j,p)}$ is also a $SU(2)\times P$'s irreducible representation of $2j+1$ dimensions, $\tilde{D}_{SU(2)\times P}^{(j,p)}$ must be equivalent to either $D_{SU(2)\times P}^{(j,p)}$, or $D_{SU(2)\times P}^{(j,-p)}$ under a unitary basis transformation $U^{(j, p)}$. If $\tilde{D}_{SU(2)\times P}^{(j,p)}$ is equivalent to $D_{SU(2)\times P}^{(j,-p)}$, then, for any $u_{\vec{\phi}}$, $v_\rho$,
\begin{equation}\label{eq:SU2*P impossible equivalence theta basis}
    \begin{aligned}
        \tilde{D}_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho)) &= U^{(j,p)\dagger}D_{SU(2)\times P}^{(j,-p)}((u_{\vec{\phi}}, v_\rho))U^{(j,p)} \\
        D^{(j)\ast}_{SU(2)}(u_{\vec{\phi}})\cdot p^\rho &= U^{(j,p)\dagger}D^{(j)}_{SU(2)}(u_{\vec{\phi}})U^{(j,p)}\cdot (-p)^\rho \\
        D^{(j)\ast}_{SU(2)}(u_{\vec{\phi}}) &= U^{(j,p)\dagger}D^{(j)}_{SU(2)}(u_{\vec{\phi}})U^{(j,p)}\cdot (-1)^\rho.
    \end{aligned}
\end{equation}
However, this is only possible when $D^{(j)\ast}_{SU(2)}$ is a zero matrix which is impossible since any representation is invertible by definition. Therefore, $\tilde{D}_{SU(2)\times P}^{(j,p)}$ must equivalent to $D_{SU(2)\times P}^{(j,p)}$, and $U^{(j,p)}$ is independent of $p$ (in the sense that any $U$ that satisfies equation \ref{eq:SU2*P impossible equivalence theta basis} for $p=1$ also satisfies for $p=-1$, and vice versa) where we will drop this superscript from here on. Similarly, after we substitute $D_{SU(2)\times P}^{(j,p)}$ into equation \ref{eq:theta theta SU2*P basis equivalence}, we can see that $\Theta^{(j,p)}$ is also independent of $p$. 

Hence, we can rewrite equation \ref{eq:modify SU2*P irreps}, and \ref{eq:theta theta SU2*P basis equivalence} as
\begin{equation}\label{eq:modify SU2*P irreps drop p}
    \tilde{D}_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho)) = D_{SU(2)\times P}^{(j,p)\ast}((u_{\vec{\phi}}, v_\rho))=U^{(j)\dagger} D_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho))U^{(j)},
\end{equation}
and
\begin{equation}\label{eq:theta theta SU2*P basis equivalence drop p}
   D_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho)) = \Theta^{(j)\dagger} D_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho))\Theta^{(j)}.
\end{equation}
Because $D_{SU(2)\times P}^{(j,p)}$ is irreducible, from Schur's second lemma (equation \ref{eq:Schur's second lemma}), $\Theta^{(j)}$ must equal a constant $t I$ for some $t\in\mathbb{C}$,
\begin{equation}\label{eq:SU2*P basis equivalence}
    \Theta^{(j)} = tI,
\end{equation}
where, since $\Theta^{(j)}$ is unitary, $|t|=1$. However, from equation \ref{eq:evaluate theta equivalence of theta theta equivalence},
\begin{equation}\label{eq:t condition}
    \begin{aligned}
        U^{(j)\dagger}\Theta^{(j)}U^{(j)} &= \Theta^{(j)\ast} \\
        U^{(j)\dagger}tIU^{(j)} &= t^\ast I \\
        t &= t^\ast,
    \end{aligned}
\end{equation}
or $t\in\mathbb{R}$. Combining with $|t|=1$, this means that $t\in\{-1, 1\}$. Hence, from equation \ref{eq:G basis equivalence}, we know that the chosen $U^{(j)}$ must satisfy
\begin{equation}\label{eq:U condition}
    U^{(j)}U^{(j)\ast} = \lambda\Theta^{(j)}=t\lambda I=\pm I.
\end{equation}

To see that this is the case, consider a matrix
\begin{equation}\label{eq:U}
    \left[U^{(j)}\right]_{a, b} = i^{2(a-j)}\delta_{a,2j-b}.
\end{equation}
with its inverse (adjoint)
\begin{equation}
    \left[U^{(j)\dagger}\right]_{a,b} = (-i)^{2(b-j)}\delta_{b,2j-a}.
\end{equation}\label{eq:Udagger}
This matrix is actually a unitary matrix since
\begin{equation}\label{eq:U unitary}
    \begin{aligned}
        \left[U^{(j)\dagger}U^{(j)}\right]_{a, b} &= \sum_c\left((-i)^{2(c-j)}\delta_{c,2j-a}\right)\left(i^{2(c-j)}\delta_{c,2j-b}\right) \\
        &= \delta_{2j-a,2j-b} = \delta_{a,b}, \\
        \left[U^{(j)}U^{(j)\dagger}\right]_{a, b} &= \sum_c\left(i^{2(a-j)}\delta_{a,2j-c}\right)\left((-i)^{2(b-j)}\delta_{b,2j-c}\right) \\
        &= i^{2(a-b)}\delta_{a,b} = \delta_{a,b}.
    \end{aligned}
\end{equation}
From this matrix, we can see its transformation of $J^{(j)}_z$ as
\begin{equation}\label{eq:Udagger Jz U}
    \begin{aligned}
        \left[U^{(j)\dagger}J_z^{(j)}U^{(j)}\right]_{a,b} &= \sum_{c,d}\left((-i)^{2(c-j)}\delta_{c,2j-a}\right)\left((c-j)\delta_{c,d}\right)\left(i^{2(d-j)}\delta_{d,2j-b}\right) \\
        &= \sum_{c}(-i)^{2(c-j)}\delta_{c,2j-a}(c-j)\delta_{c,2j-b}i^{2(j-b)} \\
        &= (-i)^{2(j-a)}(j-a)\delta_{a, b}i^{2(j-b)} \\
        &= -(a-j)\delta_{a,b} \\
        &= \left[-J_z^{(j)}\right]_{a,b},
    \end{aligned}
\end{equation}
of $J^{(j)}_+$ as
\begin{equation}\label{eq:Udagger J+ U}
    \begin{aligned}
        \left[U^{(j)\dagger}J_+^{(j)}U^{(j)}\right]_{a,b} &= \sum_{c,d}\left((-i)^{2(c-j)}\delta_{c,2j-a}\right)\left(\sqrt{j(j+1)-(c-j)(d-j)}\delta_{c,d+1}\right)\left(i^{2(d-j)}\delta_{d,2j-b}\right) \\
        &= \sum_{c}(-i)^{2(c-j)}\delta_{c,2j-a}\sqrt{j(j+1)-(c-j)(j-b)}\delta_{c,2j-b+1}i^{2(j-b)} \\
        &= (-i)^{2(j-a)}\sqrt{j(j+1)-(j-a)(j-b)}\delta_{2j-a,2j-b+1}i^{2(j-b)} \\
        &= i^{2(a-b)}\sqrt{j(j+1)-(a-j)(b-j)}\delta_{a+1,b} \\
        &= -\sqrt{j(j+1)-(a-j)(b-j)}\delta_{a+1,b} \\
        &= \left[-J_+^{(j)\top}\right]_{a,b} = \left[-J_-^{(j)}\right]_{a,b},
    \end{aligned}
\end{equation}
and $J^{(j)}_-$ as
\begin{equation}\label{eq:Udagger J- U}
    \begin{aligned}
        U^{(j)\dagger}J_-^{(j)}U^{(j)} &= U^{(j)\dagger}J_+^{(j)\dagger}U^{(j)} \\
        &= \left(U^{(j)\dagger}J_+^{(j)}U^{(j)}\right)^\dagger \\
        &= -J_-^{(j)\dagger} = -J_+^{(j)}.
    \end{aligned}
\end{equation}
This also directly implies that
\begin{equation}\label{eq:Udagger Js U}
    \begin{aligned}
        U^{(j)\dagger}J_x^{(j)}U^{(j)} &= -J_x^{(j)} \\
        U^{(j)\dagger}J_y^{(j)}U^{(j)} &= J_y^{(j)} \\
        U^{(j)\dagger}J_z^{(j)}U^{(j)} &= -J_z^{(j)}
    \end{aligned}.
\end{equation}
Therefore,
\begin{equation}\label{eq:U basis theta basis equivalence}
    \begin{aligned}
        U^\dagger D_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho))U &= U^{(j)\dagger}\exp(-i\vec{J}^{(j)}\cdot\vec{\phi})U^{(j)}\cdot p^\rho \\ 
        &= U^{(j)\dagger}\exp(-i(J_x^{(j)}\phi_x+J_y^{(j)}\phi_y+J_z^{(j)}\phi_z))U^{(j)}\cdot p^\rho \\
        &= \exp(i(J_x^{(j)}\phi_x-J_y^{(j)}\phi_y+J_z^{(j)}\phi_z))\cdot p^\rho \\
        &= D_{SU(2)\times P}^{(j,p)\ast}((u_{\vec{\phi}}, v_\rho)) \\
        &= \tilde{D}_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho)),
    \end{aligned}
\end{equation}
as required. We can also check the condition from equation \ref{eq:U condition} such that
\begin{equation}\label{eq:check U condition}
    \begin{aligned}
        \left[U^{(j)}U^{(j)\ast}\right]_{a,b} &= \sum_{c}\left(i^{2(a-j)}\delta_{a,2j-c}\right)\left((-i)^{2(c-j)}\delta_{c,2j-b}\right) \\
        &= i^{2(a-j)}\delta_{a,b}(-i)^{2(j-b)} \\
        &= i^{2(a+b-2j)}\delta_{a,b} \\
        &= i^{4a}i^{-4j}\delta_{a,b} \\
        &= (-1)^{-2j}\delta_{a,b} \\
        &= \left[(-1)^{-2j}I\right]_{a,b}.
    \end{aligned}
\end{equation}
This, together with equation \ref{eq:U condition}, gives the condition for $\lambda$ as
\begin{equation}\label{eq:lambda condition}
    \lambda = (-1)^{-2j}/t.
\end{equation}

With all these results, we can now write the corepresentation of $SU(2)\ast P\ast T$ in $\{\ket{j,m}_p\}\cup\{U^{(j)\dagger}\theta\ket{j,m}_p\}$ basis as,
\begin{equation}\label{eq:SU2*P*T Coreps simplify change basis}
    \begin{aligned}
        D_{SU(2)\ast P\ast T}^{(j,p)}((u_{\vec{\phi}}, v_\rho)) &= D_{SU(2)\times P\times T}^{(j,p)}((u_{\vec{\phi}}, v_\rho, w_0)) \\
        &= \begin{bmatrix}
            D_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho)) & 0 \\
                0 & D_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho))  
            \end{bmatrix}, \\
        D_{SU(2)\ast P\ast T}^{(j,p)}(\theta) &= D_{SU(2)\times P\times T}^{(j,p)}((u_{\vec{0}},u_0,w_1)) \\
        &= \begin{bmatrix}
                0 & (-1)^{2j}tU^{(j)} \\
                U^{(j)} & 0 
            \end{bmatrix}
    \end{aligned}
\end{equation}
where $u_{\vec{\phi}}\in SU(2)$, $v_\rho\in P$, $w_\tau\in T$, $j\in \{0, 1/2, 1, 3/2, ...\}$, $p\in\{-1, 1\}$, $t\in\{-1, 1\}$, and the irreducible representations $D_{SU(2)\times P}^{(j,p)}$ are in standard basis. Note that, equation \ref{eq:SU2*P*T Coreps simplify change basis} can be use for constructing any members of $SU(2)\ast P\ast T$ according to combination rules in equation \ref{eq:G*T composition} as well as the commutation property between members from different groups of $SU(2)$, $P$, and $T$.

The last thing we need to do is checking the reducibility of this corepresentation. The first thing we immediately notice from equation \ref{eq:SU2*P*T Coreps simplify change basis} is that, because $D_{SU(2)\times P}^{(j,p)}$ is irreducible, $D_{SU(2)\ast P\ast T}^{(j,p)}$ can only be either irreducible, or reducible into exactly two $2j+1$ dimensional subspaces. Suppose there exist a unitary transformation $M$ that block diagonalizes $D_{SU(2)\ast P\ast T}^{(j,p)}$. Since $D_{SU(2)\ast P\ast T}^{(j,p)}((u_{\vec{\phi}}, v_\rho))$ is already block diagonalized, one possible class of $M$ is the transformation of basis $\{\ket{j,m}_p\}$ and $\{U^{(j)\dagger}\theta\ket{j,m}_p\}$ separately, i.e. $M$ is a block diagonal of two $2j+1$ dimensional unitary transformation that change $D_{SU(2)\ast P\ast T}^{(j,p)}((u_{\vec{\phi}}, v_\rho))$'s to other equivalent irreducible representations. Such class of $M$ is impossible to block diagonalizes $D_{SU(2)\ast P\ast T}^{(j,p)}(\theta)$ where it needs off block diagonal terms. Hence, we can consider only $M$ that
\begin{equation}\label{eq:M block diagonalize SU2*P}
    \begin{aligned}
        M^\dagger D_{SU(2)\ast P\ast T}^{(j,p)}((u_{\vec{\phi}}, v_\rho))M &= D_{SU(2)\ast P\ast T}^{(j,p)}((u_{\vec{\phi}}, v_\rho)) \\
        D_{SU(2)\ast P\ast T}^{(j,p)}((u_{\vec{\phi}}, v_\rho))M &= MD_{SU(2)\ast P\ast T}^{(j,p)}((u_{\vec{\phi}}, v_\rho)).
    \end{aligned}
\end{equation}

Consider, a general $M$,
\begin{equation}\label{eq:general M}
    M = \begin{bmatrix}
        A & B \\
        C & D
    \end{bmatrix}.
\end{equation}
Substituting equation \ref{eq:SU2*P*T Coreps simplify change basis}, and \ref{eq:general M} into \ref{eq:M block diagonalize SU2*P}, we get
\begin{equation}\label{eq:substitute M}
    \begin{bmatrix}
        AD_{SU(2)\times P}^{(j,p)} & BD_{SU(2)\times P}^{(j,p)} \\
        CD_{SU(2)\times P}^{(j,p)} & DD_{SU(2)\times P}^{(j,p)}  
        \end{bmatrix} = \begin{bmatrix}
            D_{SU(2)\times P}^{(j,p)}A & D_{SU(2)\times P}^{(j,p)}B \\
            D_{SU(2)\times P}^{(j,p)}C & D_{SU(2)\times P}^{(j,p)}D  
            \end{bmatrix}.
\end{equation}
Because $D_{SU(2)\times P}^{(j,p)}$ is irreducible, from Schur's second lemma (equation \ref{eq:Schur's second lemma}),
\begin{equation}\label{eq:M conditions}
    M = \begin{bmatrix}
        aI & bI \\
        cI & dI
    \end{bmatrix} = \begin{bmatrix}
        a & b \\
        c & d
    \end{bmatrix}\otimes I \triangleq m\otimes I
\end{equation}
where $a, b, c, d\in\mathbb{C}$, and $m$ is a 2 by 2 unitary matrix. Then, we use this $M$ to try block diagonalizing $D_{SU(2)\ast P\ast T}^{(j,p)}(\theta)$,
\begin{equation}\label{eq:M block diagonalize T}
    \begin{aligned}
        M^\dagger D_{SU(2)\ast P\ast T}^{(j,p)}(\theta)M^\ast &= \left(m^\dagger\otimes I\right)\left(\begin{bmatrix}0&1/\lambda\\1&0\end{bmatrix}\otimes U^{(j)}\right)\left(m^\ast\otimes I\right) \\
        &= \left(m^\dagger\begin{bmatrix}0&1/\lambda\\1&0\end{bmatrix}  m^\ast\right)\otimes U^{(j)} \\
        &= \begin{bmatrix}(1+1/\lambda)a^\ast c^\ast & a^\ast d^\ast/\lambda + b^\ast c^\ast \\ a^\ast d^\ast + b^\ast c^\ast/\lambda & (1+1/\lambda)b^\ast d^\ast\end{bmatrix} \otimes U^{(j)}.
    \end{aligned}
\end{equation}
From equation \ref{eq:M block diagonalize T}, it is clear that, when $1/\lambda=(-1)^{2j}t=-1$, the block diagonal terms vanish, i.e. it is impossible to be block diagonalized. In other words, equation \ref{eq:SU2*P*T Coreps simplify change basis} is the irreducible corepresentation of $SU(2)\ast P\ast T$ for the cases that $(-1)^{2j}t=-1$.

As for the case that $1/\lambda=(-1)^{2j}t=1$, consider a choice of $m$,
\begin{equation}\label{eq:m lambda one}
    m = \dfrac{1}{\sqrt{2}}\begin{bmatrix}
        i & 1 \\
        -i & 1
    \end{bmatrix}.
\end{equation}
Then, substituting this $m$ into equation \ref{eq:M block diagonalize T}, for $1/\lambda=1$, gets
\begin{equation}\label{eq:M block diagonalized T}
    \begin{aligned}
        M^\dagger D_{SU(2)\ast P\ast T}^{(j,p)}(\theta)M^\ast &= \begin{bmatrix}2a^\ast c^\ast & a^\ast d^\ast + b^\ast c^\ast \\ a^\ast d^\ast + b^\ast c^\ast & 2b^\ast d^\ast\end{bmatrix} \otimes U^{(j)} \\
        &= \dfrac{1}{2}\begin{bmatrix}2 & i + -i \\ i + -i & 2\end{bmatrix} \otimes U^{(j)} \\
        &= \begin{bmatrix}U^{(j)} & 0 \\ 0 & U^{(j)}\end{bmatrix}.
    \end{aligned}
\end{equation}
We can see that the corepresentation is reducible into two equivalent representations with linearly dependent bases. Hence, the irreducible corepresentation of $SU(2)\ast P\ast T$ for the cases that $(-1)^{2j}t=1$ in $\left\{\left(\ket{j,m}_p+U^{(j)\dagger}\theta\ket{j,m}_p\right)/\sqrt{2}\right\}$ basis is,
\begin{equation}\label{eq:SU2*P*T Coreps lambda one}
    \begin{aligned}
        D_{SU(2)\ast P\ast T}^{(j,p)}((u_{\vec{\phi}}, v_\rho))
        &= D_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho)), \\
        D_{SU(2)\ast P\ast T}^{(j,p)}(\theta) 
        &= U^{(j)}.
    \end{aligned}
\end{equation}

From equation \ref{eq:SU2*P*T Coreps simplify change basis}, and \ref{eq:SU2*P*T Coreps lambda one}, we can see that it would be convenience to write those irreducible corepresentations in the common tensor product form such that
\begin{equation}\label{eq:SU2*P*T Coreps generalized}
    \begin{aligned}
        D_{SU(2)\ast P\ast T}^{(j,p)}((u_{\vec{\phi}}, v_\rho))
        &= \left(E^{(j,t)}\right)^0\otimes D_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho)), \\
        D_{SU(2)\ast P\ast T}^{(j,p)}(\theta) 
        &= E^{(j,t)}\otimes U^{(j)}
    \end{aligned}
\end{equation}
where
\begin{equation}\label{eq:E}
    E^{(j,t)} = \begin{cases}
        1 &, t = (-1)^{2j} \\
        \begin{bmatrix}0&-1\\1&0\end{bmatrix} &, t = (-1)^{2j+1}
    \end{cases}.
\end{equation}

From these results, we can see that $\lambda$, which can be associated with $j$, and $t$, fully specifies the irreducible corepresentation. Hence, the irreducible corepresentation of the combined $SU(2)$, $P$, and $T$ symmetries can be written, labeled with $j$, $p$, and $t$, as, for all $u_{\vec{\phi}}\in SU(2)$, $v_\rho \in P$, and $w_\tau \in T$,
\begin{equation}\label{eq:SU2*P*T IrCoreps}
    \begin{aligned}
        D^{(j,p,t)}_{SU(2)\ast P\ast T}(u_{\vec{\phi}} v_\rho w_\tau) &= D^{(j,p,t)}_{SU(2)\times P\times T}((u_{\vec{\phi}},v_\rho,w_\tau)) \\
        &= D^{(j,p,t)}_{SU(2)\times P\times T}((u_{\vec{\phi}},v_\rho,w_0))\cdot D^{(j,p,t)}_{SU(2)\times P\times T}((u_{\vec{0}},v_0,w_1)^\tau) \\
        &= \left(E^{(j,t)}\right)^\tau\otimes D_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho))\cdot\left(U^{(j)}U^{(j)\ast}\right)^{\left\lfloor \tau/2\right\rfloor}\cdot\left(U^{(j)}\right)^{\tau\bmod 2} \\
        &= \left(E^{(j,t)}\right)^\tau\otimes D_{SU(2)\times P}^{(j,p)}((u_{\vec{\phi}}, v_\rho))\cdot(-1)^{2j\left\lfloor \tau/2\right\rfloor}\cdot\left(U^{(j)}\right)^{\tau\bmod 2} \\
        &= \left(E^{(j,t)}\right)^{\tau\bmod 4}\otimes(-1)^{2j\left\lfloor \tau/2\right\rfloor}p^\rho\exp(-i\vec{J}^{(j)}\cdot\vec{\phi})\cdot \left(U^{(j)}\right)^{\tau\bmod 2}
    \end{aligned}
\end{equation}
where $\vec{\phi}\in\mathbb{R}^3$, $\rho,\tau\in\mathbb{Z}_{0+}$ $j\in\{0, 1/2, 1, 3/2, ...\}$, and $p, t\in\{-1, 1\}$. Note that the corepresentation basis for each $t$ is different by the transformation of $m$ in equation \ref{eq:m lambda one}.

\newpage
\section{Tensor Product of Representations}

\subsection{Tensor Product as Composite System Representation}

\subsection{Tensor Product Reduction}

\subsection{Tensor Product of $SU(2)\times P\times T$'s Irreducible Corepresentations}
Consider two irreducible corepresentations of $SU(2)\times P\times T$ with labels $(j_1, p_1, t_1)$, and $(j_2, p_2, t_2)$ from equation \ref{eq:SU2*P*T IrCoreps}. For neatness, we will omit the subscripts when the corepresentation is for $SU(2)\times P\times T$, i.e. $D^{(j,p,t)}\triangleq D^{(j,p,t)}_{SU(2)\times P\times T}$.Their tensor product is, for all $u_{\vec{\phi}}\in SU(2)$, $v_\rho \in P$, and $w_\tau \in T$,
\begin{equation}
    \begin{aligned}
        &D^{(j_1,p_1,t_1)}((u_{\vec{\phi}}, v_\rho, w_\tau))\otimes D^{(j_2,p_2,t_2)}((u_{\vec{\phi}}, v_\rho, w_\tau)) \\
        &=  \begin{multlined}
                D^{(j_1,p_1,t_1)}((u_{\vec{\phi}}, v_\rho, w_0))\cdot D^{(j_1,p_1,t_1)}((u_{\vec{0}}, v_0, w_\tau))\\ 
                \otimes D^{(j_2,p_2,t_2)}((u_{\vec{\phi}}, v_\rho, w_0))\cdot D^{(j_2,p_2,t_2)}((u_{\vec{0}}, v_0, w_\tau))
            \end{multlined} \\
        &=  \begin{multlined}
                \left(D^{(j_1,p_1,t_1)}((u_{\vec{\phi}}, v_\rho, w_0)) \otimes D^{(j_2,p_2,t_2)}((u_{\vec{\phi}}, v_\rho, w_0))\right) \\
                \cdot \left(D^{(j_1,p_1,t_1)}((u_{\vec{0}}, v_0, w_1)) \otimes D^{(j_2,p_2,t_2)}((u_{\vec{0}}, v_0, w_1))\right)^\tau
            \end{multlined}
    \end{aligned}
\end{equation}
where $\vec{\phi}\in\mathbb{R}^3$, $\rho,\tau\in\mathbb{Z}_{0+}$ $j\in\{0, 1/2, 1, 3/2, ...\}$, and $p, t\in\{-1, 1\}$. 


\end{document}